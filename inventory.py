import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import io
from supabase import create_client, Client
import math

# --- [1] ë¡œê·¸ì¸ ë³´ì•ˆ ---
def check_password():
    if 'password_correct' not in st.session_state:
        st.session_state.password_correct = False
    if st.session_state.password_correct:
        return True
    
    st.set_page_config(page_title="ì¬ê³ ê´€ë¦¬(ì§„ë‹¨)", layout="wide")
    st.title("ğŸ­ ë””ì§€íƒ€ìŠ¤ ì°½ê³  ì¬ê³ ê´€ë¦¬ (Ver.11.2 - ì§„ë‹¨ëª¨ë“œ)")
    pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if st.button("ë¡œê·¸ì¸"):
        if pwd == "1234": 
            st.session_state.password_correct = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    return False

if not check_password():
    st.stop()

# --- [2] Supabase ì—°ê²° ì„¤ì • ---
@st.cache_resource
def init_connection():
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["key"]
        return create_client(url, key)
    except Exception as e:
        st.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

supabase = init_connection()

# --- [ê°•ì œ ì´ˆê¸°í™” ë²„íŠ¼] ---
if st.button("ğŸ”„ ìºì‹œ ë°ì´í„° ê°•ì œ ì‚­ì œ ë° ìƒˆë¡œê³ ì¹¨ (í´ë¦­)", type="primary", use_container_width=True):
    st.cache_data.clear()
    st.rerun()

# --- [í•µì‹¬] ëŒ€ìš©ëŸ‰ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì—ëŸ¬ ì§„ë‹¨ í¬í•¨) ---
def fetch_all_data(table_name):
    if not supabase: return []
    all_data = []
    page_size = 5000 # í•œ ë²ˆì— 5000ê°œ ìš”ì²­
    offset = 0
    
    while True:
        try:
            # 5000ê°œì”© ëŠì–´ì„œ ìš”ì²­
            response = supabase.table(table_name).select("*").range(offset, offset + page_size - 1).execute()
            data = response.data
            
            if not data:
                break
                
            all_data.extend(data)
            
            # ê°€ì ¸ì˜¨ ê°œìˆ˜ê°€ ìš”ì²­ë³´ë‹¤ ì ìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€ì„
            if len(data) < page_size:
                break
                
            offset += page_size
        except Exception as e:
            # [ì§„ë‹¨] ì—ëŸ¬ ë°œìƒ ì‹œ ë©ˆì¶”ì§€ ë§ê³  ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
            st.error(f"âš ï¸ {table_name} ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (offset: {offset}): {e}")
            break
            
    return all_data

# --- [3] ë°ì´í„° ë¡œë“œ (ìºì‹±) ---
@st.cache_data(ttl=3600)
def load_data_from_db():
    if not supabase: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    try:
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        with st.spinner("ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)"):
            data_m = fetch_all_data("í’ˆëª©í‘œ")
            df_m = pd.DataFrame(data_m)
            
            data_map = fetch_all_data("ë§¤í•‘ì •ë³´")
            df_map = pd.DataFrame(data_map)
            
            data_l = fetch_all_data("ì…ì¶œê³ ")
            df_l = pd.DataFrame(data_l)
            
            data_d = fetch_all_data("ìƒì„¸ë‚´ì—­") 
            df_d = pd.DataFrame(data_d) 

        for df in [df_m, df_map, df_l, df_d]:
            if not df.empty:
                df.columns = [c.lower() for c in df.columns]

        return df_m, df_map, df_l, df_d
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì „ì²´ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

def clear_cache():
    st.cache_data.clear()

# --- [4] ì¬ê³  í˜„í™© ê³„ì‚° ---
@st.cache_data(show_spinner=False)
def calculate_stock_snapshot(df_log, df_mapping, df_master, df_details):
    if df_log.empty: return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    last_stat = df_log.sort_values('id').groupby('boxë²ˆí˜¸').tail(1)
    stock_boxes = last_stat[last_stat['êµ¬ë¶„'].isin(['ì…ê³ ', 'ì´ë™'])].copy()
    
    if not stock_boxes.empty:
        stock_boxes['match_key'] = stock_boxes['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
    
    if not df_mapping.empty:
        df_mapping['match_key'] = df_mapping['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
        if 'í’ˆëª©ì½”ë“œ' in df_mapping.columns:
            df_mapping['í’ˆëª©ì½”ë“œ'] = df_mapping['í’ˆëª©ì½”ë“œ'].astype(str).str.strip().str.upper()

    if not df_master.empty and 'í’ˆëª©ì½”ë“œ' in df_master.columns:
        df_master['í’ˆëª©ì½”ë“œ'] = df_master['í’ˆëª©ì½”ë“œ'].astype(str).str.strip().str.upper()

    merged = pd.merge(stock_boxes, df_mapping, on='match_key', how='left', suffixes=('', '_map'))
    merged['ìœ„ì¹˜'] = merged['ìœ„ì¹˜'].fillna('ë¯¸ì§€ì •').replace('', 'ë¯¸ì§€ì •')
    merged['íŒŒë ›íŠ¸'] = merged['íŒŒë ›íŠ¸'].fillna('ì´ë¦„ì—†ìŒ').replace('', 'ì´ë¦„ì—†ìŒ')
    
    if not df_master.empty and 'í’ˆëª©ì½”ë“œ' in merged.columns:
        merged = pd.merge(merged, df_master, on='í’ˆëª©ì½”ë“œ', how='left')

    filtered_details = pd.DataFrame()
    if not df_details.empty:
        df_details['match_key'] = df_details['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
        active_keys = stock_boxes['match_key'].unique()
        filtered_details = df_details[df_details['match_key'].isin(active_keys)].copy()
        
        loc_info = stock_boxes[['match_key', 'ìœ„ì¹˜', 'íŒŒë ›íŠ¸']]
        filtered_details = pd.merge(filtered_details, loc_info, on='match_key', how='left')
        
        if 'match_key' in filtered_details.columns: del filtered_details['match_key']
            
    return stock_boxes, merged, filtered_details

# --- ë°ì´í„° ì—…ë¡œë“œ ---
def chunked_upsert(table_name, df, key_col, batch_size=5000):
    if not supabase: return False
    if df.empty: return False
    try:
        df = df.astype(str)
        if key_col in df.columns: df[key_col] = df[key_col].str.strip().str.upper()
        df = df.where(pd.notnull(df), None)
        total_rows = len(df)
        chunks = math.ceil(total_rows / batch_size)
        my_bar = st.progress(0, text=f"{table_name} ì—…ë¡œë“œ...")
        for i in range(chunks):
            start = i * batch_size
            end = start + batch_size
            chunk = df.iloc[start:end]
            data = chunk.to_dict(orient='records')
            supabase.table(table_name).upsert(data, on_conflict=key_col).execute()
            my_bar.progress(min((i+1)/chunks, 1.0))
        my_bar.empty()
        return True
    except Exception as e:
        st.error(f"ì‹¤íŒ¨: {e}")
        return False

def chunked_insert(table_name, df, batch_size=5000):
    if not supabase: return False
    if df.empty: return False
    try:
        df = df.where(pd.notnull(df), None)
        total_rows = len(df)
        chunks = math.ceil(total_rows / batch_size)
        my_bar = st.progress(0, text=f"{table_name} ì¶”ê°€...")
        for i in range(chunks):
            start = i * batch_size
            end = start + batch_size
            chunk = df.iloc[start:end]
            data = chunk.to_dict(orient='records')
            supabase.table(table_name).insert(data).execute()
            my_bar.progress(min((i+1)/chunks, 1.0))
        my_bar.empty()
        return True
    except Exception as e:
        st.error(f"ì‹¤íŒ¨: {e}")
        return False

def insert_log(new_data_list):
    if not supabase: return False
    try:
        cleaned_list = []
        for item in new_data_list:
            cleaned_list.append({
                "ë‚ ì§œ": item.get("ë‚ ì§œ"),
                "êµ¬ë¶„": item.get("êµ¬ë¶„"),
                "ì…ê³ êµ¬ë¶„": item.get("ì…ê³ êµ¬ë¶„", ""),
                "boxë²ˆí˜¸": str(item.get("Boxë²ˆí˜¸")).strip().upper(), 
                "ìœ„ì¹˜": item.get("ìœ„ì¹˜", ""),
                "íŒŒë ›íŠ¸": item.get("íŒŒë ›íŠ¸", "")
            })
        supabase.table("ì…ì¶œê³ ").insert(cleaned_list).execute()
        clear_cache()
        return True
    except Exception as e:
        st.error(f"ì‹¤íŒ¨: {e}")
        return False

# --- ì¼ì • ê´€ë¦¬ ---
def fetch_schedules():
    if not supabase: return []
    try:
        res = supabase.table("schedule").select("*").execute()
        events = []
        for item in res.data:
            events.append({
                "id": str(item["id"]),
                "title": item["title"],
                "start": item["start_time"],
                "end": item.get("end_time", ""),
                "allDay": False
            })
        return events
    except Exception as e:
        st.error(f"ì¼ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def add_schedule(title, start_time):
    if not supabase: return
    try:
        supabase.table("schedule").insert({"title": title, "start_time": start_time}).execute()
        return True
    except Exception as e:
        st.error(f"ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return False

def update_schedule(id, title, start_time):
    if not supabase: return
    try:
        supabase.table("schedule").update({"title": title, "start_time": start_time}).eq("id", id).execute()
        return True
    except Exception as e:
        st.error(f"ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

def delete_schedule(id):
    if not supabase: return
    try:
        supabase.table("schedule").delete().eq("id", id).execute()
        return True
    except Exception as e:
        st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

# --- ìœ í‹¸ë¦¬í‹° ---
def init_session_state():
    if 'scan_buffer' not in st.session_state: st.session_state.scan_buffer = []
    if 'proc_msg' not in st.session_state: st.session_state.proc_msg = None
    if 'selected_rack' not in st.session_state: st.session_state.selected_rack = None

def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

def get_sample_file():
    sample_data = {'ë‚ ì§œ': [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],'ì´ë™êµ¬ë¶„': ['ì…ê³ '],'ì…ê³ êµ¬ë¶„': ['ì¼ë°˜ì² ê±°'],'Boxë²ˆí˜¸': ['V2024...'],'ìœ„ì¹˜': ['1-2-7'],'íŒŒë ›íŠ¸': ['P-01']}
    return to_excel(pd.DataFrame(sample_data))

def buffer_scan(df_master, df_mapping, df_log, df_details):
    scan_val = str(st.session_state.scan_input).strip().upper()
    mode = st.session_state.work_mode
    curr_loc = str(st.session_state.get('curr_location', '')).strip()
    curr_pal = str(st.session_state.get('curr_palette', '')).strip()
    if not scan_val: return

    disp_name, disp_spec, disp_qty, p_code = "ì •ë³´ì—†ìŒ", "ê·œê²©ì—†ìŒ", 0, ""
    
    # 1. ë§¤í•‘ í™•ì¸
    if not df_mapping.empty and 'boxë²ˆí˜¸' in df_mapping.columns:
        df_mapping['temp_key'] = df_mapping['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
        map_info = df_mapping[df_mapping['temp_key'] == scan_val]
        if not map_info.empty:
            p_code = str(map_info.iloc[0]['í’ˆëª©ì½”ë“œ']).strip()
            disp_qty = map_info.iloc[0]['ìˆ˜ëŸ‰']
            if not df_master.empty and 'í’ˆëª©ì½”ë“œ' in df_master.columns:
                df_master['temp_key'] = df_master['í’ˆëª©ì½”ë“œ'].astype(str).str.strip().str.upper()
                m_info = df_master[df_master['temp_key'] == p_code.upper()]
                if not m_info.empty:
                    disp_name = m_info.iloc[0]['í’ˆëª…']
                    disp_spec = m_info.iloc[0]['ê·œê²©']

    # 2. ì••ì¶•ì½”ë“œ í™•ì¸
    is_compressed = False
    target_box_no = scan_val
    if p_code == "ì •ë³´ì—†ìŒ":
        if not df_details.empty and 'ì••ì¶•ì½”ë“œ' in df_details.columns:
            df_details['temp_code'] = df_details['ì••ì¶•ì½”ë“œ'].astype(str).str.strip().str.upper()
            matched = df_details[df_details['temp_code'] == scan_val]
            if not matched.empty:
                target_box_no = str(matched.iloc[0]['boxë²ˆí˜¸']).strip().upper()
                is_compressed = True
                if not df_mapping.empty:
                    df_mapping['temp_key'] = df_mapping['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
                    map_info = df_mapping[df_mapping['temp_key'] == target_box_no]
                    if not map_info.empty:
                        p_code = str(map_info.iloc[0]['í’ˆëª©ì½”ë“œ']).strip()
                        disp_qty = map_info.iloc[0]['ìˆ˜ëŸ‰']
                        if not df_master.empty:
                            m_info = df_master[df_master['temp_key'] == p_code.upper()]
                            if not m_info.empty:
                                disp_name = m_info.iloc[0]['í’ˆëª…']
                                disp_spec = m_info.iloc[0]['ê·œê²©']

    box_status, current_db_loc = "ì‹ ê·œ", "ë¯¸ì§€ì •"
    if not df_log.empty and 'boxë²ˆí˜¸' in df_log.columns:
        df_log['temp_key'] = df_log['boxë²ˆí˜¸'].astype(str).str.strip().str.upper()
        my_logs = df_log[df_log['temp_key'] == target_box_no]
        if not my_logs.empty:
            last_log = my_logs.iloc[0]
            last_action = last_log['êµ¬ë¶„']
            current_db_loc = last_log['ìœ„ì¹˜']
            if last_action in ['ì…ê³ ', 'ì´ë™']: box_status = f"ì°½ê³ ìˆìŒ({current_db_loc})"
            elif last_action == 'ì¶œê³ ': box_status = "ì¶œê³ ë¨"

    is_duplicate = (mode == "ì…ê³ " and "ì°½ê³ ìˆìŒ" in box_status)
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    msg_prefix = "ğŸ“¦ ì••ì¶•ì½”ë“œ ì¸ì‹ â†’ " if is_compressed else ""
    
    if mode == "ì¡°íšŒ(ê²€ìƒ‰)":
        msg_text = f"ğŸ” {msg_prefix}Box: {target_box_no} / {disp_name} / {disp_spec} / {disp_qty}ê°œ / {current_db_loc}"
        st.session_state.proc_msg = ("info", msg_text)
    elif mode == "ì¶œê³ ":
        if "ì°½ê³ ìˆìŒ" not in box_status:
            st.session_state.proc_msg = ("error", f"â›” ì¶œê³  ë¶ˆê°€: Box [{target_box_no}] ì¬ê³  ì—†ìŒ")
        else:
            log_entry = {'ë‚ ì§œ': now_str, 'êµ¬ë¶„': mode, 'ì…ê³ êµ¬ë¶„': '', 'Boxë²ˆí˜¸': target_box_no, 'í’ˆëª©ì½”ë“œ': p_code, 'ê·œê²©': disp_spec, 'ìˆ˜ëŸ‰': disp_qty, 'ìœ„ì¹˜': final_loc, 'íŒŒë ›íŠ¸': final_pal}
            st.session_state.scan_buffer.append(log_entry)
            st.session_state.proc_msg = ("success", f"âœ… {msg_prefix}ì¶œê³  ëŒ€ê¸°: {target_box_no}")
    else: 
        if is_duplicate:
            st.session_state.proc_msg = ("error", f"â›” ì´ë¯¸ ì…ê³ ë¨: {target_box_no}")
        else:
            final_loc = curr_loc if curr_loc else "ë¯¸ì§€ì •"
            final_pal = curr_pal if curr_pal else "ì´ë¦„ì—†ìŒ"
            log_entry = {'ë‚ ì§œ': now_str, 'êµ¬ë¶„': mode, 'ì…ê³ êµ¬ë¶„': '', 'Boxë²ˆí˜¸': target_box_no, 'í’ˆëª©ì½”ë“œ': p_code, 'ê·œê²©': disp_spec, 'ìˆ˜ëŸ‰': disp_qty, 'ìœ„ì¹˜': final_loc, 'íŒŒë ›íŠ¸': final_pal}
            st.session_state.scan_buffer.append(log_entry)
            st.session_state.proc_msg = ("success", f"âœ… {msg_prefix}{mode}: {target_box_no}")
            
    st.session_state.scan_input = ""

@st.fragment
def view_inventory_dashboard(df_log, df_mapping, df_master, df_details):
    if df_log.empty:
        st.info("ë°ì´í„° ì—†ìŒ")
        return

    stock_boxes, merged, filtered_details = calculate_stock_snapshot(df_log, df_mapping, df_master, df_details)

    req_cols = ['ë‚ ì§œ', 'êµ¬ë¶„', 'ì…ê³ êµ¬ë¶„', 'boxë²ˆí˜¸', 'ìœ„ì¹˜', 'íŒŒë ›íŠ¸', 'í’ˆëª©ì½”ë“œ', 'ê·œê²©', 'ê³µê¸‰ì—…ì²´', 'ìˆ˜ëŸ‰']
    final_cols = [c for c in req_cols if c in merged.columns]
    
    d1, d2, d3 = st.columns(3)
    with d1: st.download_button("ğŸ“¥ ì¬ê³  ìš”ì•½ ë‹¤ìš´ë¡œë“œ", to_excel(merged[final_cols]), "ì¬ê³ ìš”ì•½.xlsx", use_container_width=True)
    with d2: st.download_button("ğŸ“¥ ìƒì„¸ ë‚´ì—­ ë‹¤ìš´ë¡œë“œ (ì¬ê³ ë¶„)", to_excel(filtered_details), "ìƒì„¸ë‚´ì—­_ì¬ê³ .xlsx", use_container_width=True)
    
    st.divider()
    sc1, sc2, sc3 = st.columns([1, 1, 2])
    with sc1: search_target = st.selectbox("ê²€ìƒ‰ ê¸°ì¤€", ["ì „ì²´", "í’ˆëª©ì½”ë“œ", "ê·œê²©", "boxë²ˆí˜¸"])
    with sc2: exact_match = st.checkbox("ì •í™•íˆ ì¼ì¹˜", value=True)
    with sc3: search_query = st.text_input("ê²€ìƒ‰ì–´", key="sq")

    filtered_df = merged
    hl_list = []

    if search_query and not filtered_df.empty:
        q = search_query.strip().upper()
        if search_target == "ì „ì²´":
            if exact_match:
                mask = ((filtered_df['í’ˆëª©ì½”ë“œ'] == q) | (filtered_df['í’ˆëª…'] == q) | (filtered_df['boxë²ˆí˜¸'] == q) | (filtered_df['ê·œê²©'] == q))
            else:
                mask = (filtered_df['í’ˆëª©ì½”ë“œ'].astype(str).str.contains(q, na=False) | filtered_df['í’ˆëª…'].astype(str).str.contains(q, na=False) | filtered_df['boxë²ˆí˜¸'].astype(str).str.contains(q, na=False) | filtered_df['ê·œê²©'].astype(str).str.contains(q, na=False))
        else:
            if exact_match: mask = filtered_df[search_target] == q
            else: mask = filtered_df[search_target].astype(str).str.contains(q, na=False)
        
        filtered_df = filtered_df[mask]
        for loc in filtered_df['ìœ„ì¹˜'].unique():
            clean_loc = str(loc).strip()
            if '-' in clean_loc and 'í†µë¡œ' not in clean_loc:
                parts = clean_loc.split('-')
                if len(parts) >= 3: hl_list.append(f"{parts[0]}-{parts[2]}")
                elif len(parts) == 2: hl_list.append(f"{parts[0]}-{parts[1]}")
            else: hl_list.append(clean_loc)
    
    if st.session_state.selected_rack and not filtered_df.empty:
        sel = st.session_state.selected_rack
        hl_list.append(sel)
        def filter_loc(l):
            l = str(l).strip()
            if 'í†µë¡œ' in sel: return l == sel
            else:
                if '-' in l and 'í†µë¡œ' not in l: return l.startswith(sel.split('-')[0]) and l.endswith(sel.split('-')[-1])
                return False
        filtered_df = filtered_df[filtered_df['ìœ„ì¹˜'].apply(filter_loc)]

    c_map, c_list = st.columns([1.5, 1])
    with c_map:
        st.markdown("##### ğŸ—ºï¸ ì°½ê³  ë°°ì¹˜ë„")
        rack_summary = {}
        if not stock_boxes.empty and 'ìœ„ì¹˜' in stock_boxes.columns:
            locs = stock_boxes['ìœ„ì¹˜'].astype(str).str.strip()
            for raw_loc in locs:
                if not raw_loc or raw_loc == 'ë¯¸ì§€ì •': continue
                if 'í†µë¡œ' in raw_loc: rack_summary[raw_loc] = rack_summary.get(raw_loc, 0) + 1
                else:
                    parts = raw_loc.split('-')
                    if len(parts) >= 3: k = f"{parts[0]}-{parts[2]}"
                    elif len(parts) == 2: k = f"{parts[0]}-{parts[1]}"
                    else: k = raw_loc
                    rack_summary[k] = rack_summary.get(k, 0) + 1

        st.markdown("""
        <style>
        div[data-testid="column"] button { width: 100%; height: 40px !important; margin: 1px 0px !important; padding: 0px !important; font-size: 10px !important; font-weight: 700 !important; border-radius: 4px !important; border: 1px solid #ccc; }
        div[data-testid="column"] button:hover { border-color: #333 !important; transform: scale(1.05); z-index: 5; }
        button[kind="primary"] { background-color: #ffcdd2 !important; color: #b71c1c !important; border: 2px solid #d32f2f !important; }
        button[kind="secondary"] { background-color: #ffffff !important; color: #555 !important; }
        .rack-spacer { height: 10px; width: 100%; } 
        .rack7-label { text-align: center; font-weight: bold; color: #555; margin-bottom: 5px; font-size: 12px; }
        </style>
        """, unsafe_allow_html=True)

        def rack_click(key):
            st.
